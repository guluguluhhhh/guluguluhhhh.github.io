[{"categories":null,"content":"Extendible Hash Index 在此编程项目中，将使用可扩展哈希的变体作为哈希方案，在数据库系统中实现磁盘支持的哈希索引。 下图显示了一个可扩展哈希表，其中header页最大深度为 2，directory页最大深度为 2，存储bucket页最多包含两个条目。值被省略，并且键的哈希值显示在bucket页面中，而不是键本身。 该索引提供快速数据检索，无需搜索数据库表中的每一行，从而实现快速随机查找。实现应该支持线程安全的搜索、插入和删除（包括增长/收缩目录和拆分/合并桶）。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:1:0","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Read/Write Page Guards 在Buffer Pool Manager中， FetchPage和NewPage函数返回指向已固定页面的指针。固定机制确保页面不会被逐出，直到页面上不再有任何读写操作。为了表明内存中不再需要该页，程序员必须手动调用UnpinPage。 另一方面，如果程序员忘记调用UnpinPage ，该页将永远不会被从缓冲池中逐出。由于缓冲池实际上以较少数量的帧运行，因此将有更多的页面进出磁盘的交换。不仅性能受到影响，而且错误也很难被发现。 所以第一个任务将实现BasicPageGuard ，它存储指向BufferPoolManager和Page对象的指针。页面防护确保一旦超出范围，就会在相应的Page对象上调用UnpinPage 。请注意，它仍然应该公开一个方法，供程序员手动取消固定页面。 由于BasicPageGuard隐藏了底层Page指针，因此它还可以提供只读/写入数据 API，这些 API 提供编译时检查，以确保为每个用例正确设置is_dirty标志。 在Page类中，有用于多线程保护的latch方法。与取消固定页面类似，程序员可能会忘记在使用页面后解锁页面。为了缓解这个问题，您将实现ReadPageGuard和WritePageGuard一旦页面超出范围，它们就会自动解锁页面。 需要为所有BasicPageGuard 、 ReadPageGuard和WritePageGuard实现以下函数。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:0","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"PageGuard(PageGuard \u0026\u0026that) 移动构造函数。拷贝构造函数和拷贝赋值的目的是将一个对象复制到另一个对象，而移动构造函数和移动赋值的目的是将资源的所有权从一个对象转移到另一个对象(这通常比复制成本低得多)。实现拷贝语义时需要使用const类型的左值引用作为形参，而实现移动语义时，需要使用非const的右值形参。 转移资源所有权（之后释放原来对象对资源的管理）。 BasicPageGuard::BasicPageGuard(BasicPageGuard \u0026\u0026that) noexcept : bpm_(that.bpm_), page_(that.page_), is_dirty_(that.is_dirty_) { that.page_ = nullptr; that.bpm_ = nullptr; that.is_dirty_ = false; } ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:1","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"operator=(PageGuard \u0026\u0026that) 移动赋值运算符。 自我赋值检查。 释放被赋值对象当前持有的资源。 转移资源所有权。 auto BasicPageGuard::operator=(BasicPageGuard \u0026\u0026that) noexcept -\u003e BasicPageGuard \u0026 { if (\u0026that == this) { return *this; } Drop(); bpm_ = that.bpm_; page_ = that.page_; is_dirty_ = that.is_dirty_; that.page_ = nullptr; that.bpm_ = nullptr; that.is_dirty_ = false; return *this; } ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:2","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Drop() Unpin and/or unlatch. 如果bpm_和page_不为nullptr，执行bpm_-\u003eUnpinPage。 bpm_和page_置为nullptr。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:3","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"~PageGuard() 析构函数。 调用Drop()。 还需要为BasicPageGuard实现以下升级功能。这些函数需要保证受保护的页面在升级过程中不会被从缓冲池中逐出。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:4","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"UpgradeRead() 升级到ReadPageGuard。 如果page_不等于nullptr，上读锁RLatch()。 当前资源所有权转移给ReadPageGuard，将它返回。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:5","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"UpgradeWrite() 升级到WritePageGuard。 如果page_不等于nullptr，上写锁WLatch()。 当前资源所有权转移给WritePageGuard，将它返回。 使用新的页面防护，在BufferPoolManager中实现以下包装器。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:6","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"FetchPageBasic(page_id_t page_id) 调用FetchPage获取page，用this和page构造BasicPageGuard返回。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:7","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"FetchPageRead(page_id_t page_id) 调用FetchPage获取page，若不为nullptr则上读锁RLatch()。 用this和page构造ReadPageGuard返回。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:8","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"FetchPageWrite(page_id_t page_id) 调用FetchPage获取page，若不为nullptr则上写锁WLatch()。 用this和page构造WritePageGuard返回。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:9","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"NewPageGuarded(page_id_t *page_id) 调用NewPage获取page，用this和page构造BasicPageGuard返回。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:2:10","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Extendible Hash Table Pages 每个可扩展哈希表头/目录/桶页对应于缓冲池取出的内存页的内容（即data_部分）。每次读取或写入页面时，必须首先从缓冲池中获取页面（使用其唯一的page_id ），重新解释将其转换为相应的类型，并在读取或写入页面后取消固定该页面。也就是利用任务1的PageGuard API来实现这个目标。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:3:0","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Header Page 标头页位于基于磁盘的可扩展哈希表的第一级，并且哈希表只有一个标头页。它存储指向目录页面的逻辑子指针。你可以把它想象成一个静态的一级目录页面。它有两个字段： directory_page_ids_：目录页面 id 的数组 bucket_size_：标题页可以处理的最大深度，也就是最开始图中的header(2)。 需要实现： Init(uint32_t max_depth)：赋值max_depth_，directory_page_ids_数组中的值都置为INVALID_PAGE_ID。 HashToDirectoryIndex(uint32_t hash)：把hash右移32-max_depth_位，保留最高max_depth_位返回。 GetDirectoryPageId(uint32_t directory_idx) SetDirectoryPageId(uint32_t directory_idx, page_id_t directory_page_id) MaxSize()：左移max_depth_位，2的max_depth次方。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:3:1","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Directory Page 目录页位于基于磁盘的可扩展哈希表的第二层。它们中的每一个都存储指向桶页面的逻辑子指针，以及用于处理桶映射和动态目录增长和收缩的元数据。目录页面有以下字段： max_depth_：标题页可以处理的最大深度，对应图中directory(2/2)。 global_depth_：当前目录全局深度，对应图中directory(2/2)。 local_depths_：桶页面局部深度的数组，对应图中directory下面表格的第二列，表示最后几位相同就在同一个桶。例如，图中00和10对应的局部深度为1，他俩最后一位相同，所以在同一个桶，但01和11的局部深度为2，他俩就不在同一个桶。 bucket_page_ids_：桶页面id的数组 部分需要实现的： Init(uint32_t max_depth)：赋值max_depth_，local_depths_数组中的值都值为0，bucket_page_ids_数组中的值都置为INVALID_PAGE_ID。 HashToBucketIndex(uint32_t hash)：用与运算取hash最后global_depth_位。 GetSplitImageIndex(uint32_t bucket_idx)：可以理解为计算兄弟桶的id，将该bucket_id的最高位反转得到的值返回。 return bucket_idx + (1 \u003c\u003c (global_depth_ - 1)); IncrGlobalDepth()：首先如果已经等于max_depth_，直接return。将目录增大小扩大一倍，操作相当于把现在的内容复制一遍给新增的那部分： void ExtendibleHTableDirectoryPage::IncrGlobalDepth() { if (global_depth_ \u003e= max_depth_) { return; } // double the size of the directory for (int i = 0; i \u003c 1 \u003c\u003c global_depth_; i++) { bucket_page_ids_[(1 \u003c\u003c global_depth_) + i] = bucket_page_ids_[i]; local_depths_[(1 \u003c\u003c global_depth_) + i] = local_depths_[i]; } global_depth_++; } DecrGlobalDepth()：若已经等于0，直接return。否则减一。 CanShrink()：GD等于零返回false。检查所有LD \u003c GD。 IncrLocalDepth和DecrLocalDepth：检查大小后直接增或减。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:3:2","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Bucket Page 桶页面位于基于磁盘的可扩展哈希表的第三层。它们是实际存储键值对的。有以下字段： size_：桶中保存的键值对的数量。 max_size_：桶可以处理的最大键值对数量。 array_：大小为桶页面局部深度的数组，存储键值对数据。 部分需要实现的： Lookup(const K \u0026key, V \u0026value, const KC \u0026cmp)：查找key，如果找到了把key(array[i],first)对应的值(array[i].second)赋给value，返回true。 Insert(const K \u0026key, const V \u0026value, const KC \u0026cmp)：查找key，如果已经存在，返回false。如果key不存在，则插入到数组最后，size增加，返回true。 Remove(const K \u0026key, const KC \u0026cmp)：查找key，找到了就array_中后面的元素往前移一位，size减少，返回true。没找到返回false。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:3:3","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Extendible Hashing Implementation 实现对插入、搜索和删除的支持。要求要实现桶拆分/合并和目录增长/收缩。先了解一下实现关键点： Empty Table：第一次创建一个空哈希表时，它应该只有一个唯一的Header Page，Directory pages 和 bucket pages按需创建。 Header Indexing：通过前面的部分应该已经明白了，使用最高有效位来索引标题页中的directory_page_ids_数组。 Directory Indexing：使用最低有效位来索引目录页中的bucket_page_ids_数组。 Bucket Splitting：如果没有空间插入，则必须分裂桶。 Bucket Merging：当桶变空的时候必须尝试合并。有一些方法可以通过检查桶及其分割映像的占用情况来更积极地进行合并，但这些昂贵的检查和额外的合并可能会增加抖动。这里为了使事情相对简单，用以下规则： 只能合并空桶。 仅当其分割图像具有相同的局部深度时，桶才能与其分割图像合并。 如果合并桶的新分割镜像为空，则应继续递归合并。 Directory Growing：意思就是目录会不断增长。 Directory Shrinking：仅当每个桶的局部深度严格小于目录的全局深度时才收缩目录。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:0","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"DiskExtendibleHashTable 构造函数 主要是把传入的参数都赋值，然后用NewPageGuarded创建一个page guard，再用模版函数转换为ExtendibleHTableHeaderPage，执行init。 auto header_guard = bpm-\u003eNewPageGuarded(\u0026header_page_id_); auto header_page = header_guard.template AsMut\u003cExtendibleHTableHeaderPage\u003e(); header_page-\u003eInit(header_max_depth_); ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:1","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"GetValue auto DiskExtendibleHashTable\u003cK, V, KC\u003e::GetValue(const K \u0026key, std::vector *result, Transaction *transaction) const -\u003e bool 从标头页开始搜索：利用FetchPageRead获取header_guard，同样的方式转换为header_page，用Hash函数处理key得到hash值，然后用HashToDirectoryIndex处理得到dir_index，即可找到目录页。这里就可以Drop掉header_guard了。 若得到的目录页的PageId为INVALID_PAGE_ID，则返回false。否则获取该目录页，HashToBucketIndex得到桶的索引。接着等到成功获取到桶页面切不为INVALID_PAGE_ID的时候再Drop掉dir_guard。 最后就可以在桶里找了，用桶的LookUp函数搜索，找到了就push_back到result中，Drop掉bucket_guard，返回true。没找到就返回false。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:2","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"SplitBucket auto DiskExtendibleHashTable\u003cK, V, KC\u003e::SplitBucket(ExtendibleHTableDirectoryPage *directory, ExtendibleHTableBucketPage\u003cK, V, KC\u003e *bucket, uint32_t bucket_idx) -\u003e bool New一个新的页面作为新的桶页，并升级为WritePageGuard，如果得到的PageId为INVALID_PAGE_ID，说明分配失败，直接return false。 WritePageGuard split_bucket_guard = bpm_-\u003eNewPageGuarded(\u0026split_page_id).UpgradeWrite(); 得到分裂的新桶page，执行Init，因为它就是传入的那个bucket（执行分裂前该桶已经增加过LD了）的兄弟，所以它在目录中的索引就是GetSplitImageIndex(bucket_idx)，LD也与之相同，所以目录需要对新桶执行SetBucketPageId和SetLocalDepth。 由于桶的分裂，LD增加，使得之前存放的第一个桶里的内容需要拿出来重新分配到这两个桶里。用一个vector记录下第一个桶里的所有键值对，然后清空该桶，再根据每个键的最低有效位来选择放到哪个桶里。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:3","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Insert auto DiskExtendibleHashTable\u003cK, V, KC\u003e::Insert(const K \u0026key, const V \u0026value, Transaction *transaction) -\u003e bool 先执行GetValue(key, \u0026v, transaction)，若找到了，说明键已存在，直接返回false。 同样从标头页开始找，区别就是这里用的是FetchPageWrite，因为涉及到写。通过hash_key在标头页中得到dir_page_id。 如果dir_page_id等于INVALID_PAGE_ID，说明目录页不存在，需要新分配目录页，并初始化，我们另起一个函数InsertToNewDirectory来处理，在下面给出。否则，Drop掉header_guard，获取目录页，根据目录页和hash_key得到桶的bucket_page_id。因为目录页之后会写，不着急Drop。 同理，如果bucket_page_id等于INVALID_PAGE_ID，另起一个函数InsertToNewBucket来处理。否则，拿到桶页，用桶页的Insert函数插入，如果成功就返回true。 如果失败说明桶已满，需要分裂桶。先检查LD已经等于GD，如果是，再检查GD是否大于等于MD，如果不是，可以IncrGlobalDepth，如果也是，说明满满的了，分不了，返回false。然后就可以增加这个桶的LD了，同时增加它兄弟的LD(例如最开始图中的00和10，要加一起加)。 执行到这里，就可以开始分裂了SplitBucket，分裂失败就返回false，否则Drop掉bucket_guard和dir_guard，然后递归return Insert(..)。 // 这里两个函数其实主要是在新建有效页，让对应的索引指向有效页面，最后还是要调用Insert来重新插入。 template \u003ctypename K, typename V, typename KC\u003e auto DiskExtendibleHashTable\u003cK, V, KC\u003e::InsertToNewDirectory(ExtendibleHTableHeaderPage *header, uint32_t directory_idx, uint32_t hash, const K \u0026key, const V \u0026value) -\u003e bool { page_id_t dir_page_id = INVALID_PAGE_ID; // allocate a new directory page WritePageGuard dir_guard = bpm_-\u003eNewPageGuarded(\u0026dir_page_id).UpgradeWrite(); auto dir_page = dir_guard.AsMut\u003cExtendibleHTableDirectoryPage\u003e(); dir_page-\u003eInit(directory_max_depth_); header-\u003eSetDirectoryPageId(directory_idx, dir_page_id); auto bucket_idx = dir_page-\u003eHashToBucketIndex(hash); return InsertToNewBucket(dir_page, bucket_idx, key, value); } template \u003ctypename K, typename V, typename KC\u003e auto DiskExtendibleHashTable\u003cK, V, KC\u003e::InsertToNewBucket(ExtendibleHTableDirectoryPage *directory, uint32_t bucket_idx, const K \u0026key, const V \u0026value) -\u003e bool { page_id_t bucket_page_id = INVALID_PAGE_ID; // allocate a new bucket page WritePageGuard bucket_guard = bpm_-\u003eNewPageGuarded(\u0026bucket_page_id).UpgradeWrite(); auto bucket_page = bucket_guard.AsMut\u003cExtendibleHTableBucketPage\u003cK, V, KC\u003e\u003e(); bucket_page-\u003eInit(bucket_max_size_); directory-\u003eSetBucketPageId(bucket_idx, bucket_page_id); return bucket_page-\u003eInsert(key, value, cmp_); } ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:4","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Remove auto DiskExtendibleHashTable\u003cK, V, KC\u003e::Remove(const K \u0026key, Transaction *transaction) -\u003e bool 同样用FetchPageWrite获取标头页，然后根据hash_key得到目录页的dir_page_id，Drop掉header_guard。如果得到的是INVALID_PAGE_ID，说明目录页不存在，直接return false。 一样的操作得到桶页，如果桶页PageId为INVALID_PAGE_ID，直接return false。否则用桶页执行Remove，此时Drop掉bucket_guard。如果Remove失败，返回false。 如果Remove成功，开始检测是否需要合并。一个大循环while(LD \u003e 0)，内部先获取该桶的兄弟桶，然后判断如果俩兄弟LD不一样 or 两个都不是空桶，直接break出来。否则，这轮循环需要合并：bpm_-\u003eDeletePage掉那个空桶，LD减1，更新目录。 上一个循环结束后，合并完成。这里再一个循环，判断是否CanShrink()，如果可以就直接目录DecrGlobalDepth()，直到不能缩为止。Drop掉dir_guard。返回true。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:4:5","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Concurrency Control 多线程并发控制。注意实现过程中Fetch和Drop的时机。 ","date":"2025-01-14","objectID":"/cmu15445-extendible_hash_index/:5:0","tags":null,"title":"Cmu15445 Extendible Hash Index","uri":"/cmu15445-extendible_hash_index/"},{"categories":null,"content":"Buffer Pool 这个project是要在存储管理器中实现一个buffer pool，即缓冲池。缓冲池其实就是一块大的内存区域主内存，负责与磁盘之间来回移动物理页。它使得DBMS支持大于系统可用内存的数据库。缓冲池的操作对系统中的其他部分应该是透明的。例如，系统使用唯一标识符page_id_t想缓冲池请求页面的时候，系统不知道该页面是否位于已经在内存中，或者是需要从磁盘检索。 实现的时候需要保证线程安全。多个线程可以同时访问内部数据结构，并且必须确保关键部分收到latch的保护。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:0:0","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"LRU-K 更换策略 这个组件负责跟踪缓冲池的页面使用情况。LRUKReplacer的最大大小与缓冲池的大小相同，但并非 replacer 中的所有帧都被视为可驱逐。LRUKReplacer的大小由可驱逐帧的数量表示。 LRU-K 算法移出其后向 k 距离为replacer中所有帧的最大值的帧。向后 k 距离的计算方法是当前时间戳与第 k 次访问的时间戳之间的时间差。历史访问次数少于 k 次的帧将为其后 k 距离指定 +inf。 当多个帧具有 +inf 向后 k 距离时，实施普通的LRU。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:1:0","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Evict(frame_id_t* frame_id) -\u003e bool 驱逐具有最大向后 k 距离的帧。将帧 ID 存储在 output 参数中并返回 True。如果没有可驱逐的帧，则返回 False。 获取latch，判断如果当前大小为0，则返回false。 构建tuple(id, kthTimestamp, mostRecentTimestamp)来存储节点信息，然后创建一个vector\u003ctuple\u003e，遍历node_store_中的所有节点，把每个节点的信息用tuple的形式放进vector中。vector为空则返回false。 实现一个临时的cmp排序函数，对vector中元素进行排序std::sort(vec.begin(), vec.end(), cmp)，排在第一个的元素就是需要被驱逐的节点。清除节点历史、置为不可驱逐、replacer大小减1、赋值frame_id。 auto cmp = [](const std::tuple\u003cframe_id_t, size_t, size_t\u003e \u0026a, const std::tuple\u003cframe_id_t, size_t, size_t\u003e \u0026b) { if (std::get\u003c1\u003e(a) != std::get\u003c1\u003e(b)) { return std::get\u003c1\u003e(a) \u003e std::get\u003c1\u003e(b); } return std::get\u003c2\u003e(a) \u003c std::get\u003c2\u003e(b); }; ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:1:1","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"RecordAccess(frame_id_t frame_id) 记录在当前时间戳访问给定的帧 ID。应在 BufferPoolManager 中固定页面后调用此方法。 获取latch，frame_id不超过replacer_size_，否则throw exception。 当前时间戳加1，先在node_store_找frame_id，找到了就直接把当前时间戳添加到该帧的访问历史中，否则新建一个节点，添加访问历史，并把新节点emplace到node_store_中。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:1:2","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Remove(frame_id_t frame_id) 清除与框架关联的所有访问历史记录。仅当在 BufferPoolManager 中删除页面时，才应调用此方法。 获取latch，frame_id不超过replacer_size_，否则throw exception。 在node_store_找该帧，若没找到或者找到了但不可驱逐，直接return。 拿到该帧，清除访问历史，置为不可驱逐，replacer当前大小减1。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:1:3","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"SetEvictable(frame_id_t frame_id, bool set_evictable) 该方法控制帧是否可驱逐。它还控制 LRUKReplacer 的大小。在实现 BufferPoolManager 时当页面的 pin count 达到 0 时，其对应的帧被标记为 evictable 并且 replacer 的大小会增加。 获取latch，frame_id不超过replacer_size_，否则throw exception。 在node_store_找该帧，若没找到，直接return。 找到该帧之后，判断若是由unevictable变为evictable，则replacer当前大小加1，反之replacer当前大小减1。设置该帧可驱逐与否。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:1:4","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Disk Scheduler 该组件负责调度DiskManager上的读写操作。BufferPoolManager 可以使用磁盘调度程序disk scheduler对磁盘请求进行排队，磁盘调度程序将维护一个后台工作线程，负责处理调度的请求。 磁盘调度程序将利用共享队列来调度和处理磁盘请求。一个线程将向队列添加一个请求，磁盘调度程序的后台工作人员将处理排队的请求。项目已提供了一个Channel类 src/include/common/channel.h 以促进线程之间安全共享数据。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:2:0","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Schedule(DiskRequest r) 安排DiskManager执行的请求。 DiskRequest结构指定请求是否为读/写、数据应写入/从何处以及操作的页 ID。 DiskRequest还包含一个std::promise一旦处理请求，其值应设置为 true。 将请求添加到共享队列中 request_queue_.Put(std::make_optional\u003cDiskRequest\u003e(std::move(r))); ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:2:1","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"StartWorkerThread() 此方法负责获取排队的请求并将它们分派到DiskManager。请记住在DiskRequest的回调中设置值，以向请求发出者发出请求已完成的信号。在调用 DiskScheduler的析构函数之前，该值不应返回。 循环查看是否有请求，有请求就调用DiskManager的ReadPage或WritePage方法，然后执行回调设置值。 void DiskScheduler::StartWorkerThread() { std::optional\u003cDiskRequest\u003e request; // 是否循环看request.has_value() while ((request = request_queue_.Get(), request.has_value())) { if (request-\u003eis_write_) { disk_manager_-\u003eWritePage(request-\u003epage_id_, request-\u003edata_); } else { disk_manager_-\u003eReadPage(request-\u003epage_id_, request-\u003edata_); } request-\u003ecallback_.set_value(true); } } ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:2:2","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Disk Manager 磁盘管理器类Disk Manager从磁盘读取页面数据并将其写入磁盘。您的磁盘调度程序在处理读取或写入请求时将使用磁盘管理器的ReadPage()和WritePage()。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:3:0","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Buffer Pool Manager BufferPoolManager负责使用DiskScheduler从磁盘获取数据库页面并将其存储在内存中。当明确指示执行此操作或需要逐出页面以为新页面腾出空间时， BufferPoolManager还可以安排将脏页面写入磁盘。 实验文档中强调，这里需要理解的是：系统里所有内存的页面都是由Page对象表示，BufferPoolManager也不需要了解页面的内容，但是作为开发人员，你需要认识到Page对象只是bufferpool中内存的容器。也就是说，每个Page对象都包含了一块内存空间，用来存放从磁盘读取的物理页面的内容。当数据在磁盘上来回移动时， BufferPoolManager将重用相同的Page对象来存储数据。这意味着在系统的整个生命周期中，同一个Page对象可能包含不同的物理页。 Page对象的标识符(page_id)跟踪它包含的物理页。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:0","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"NewPage(page_id_t* page_id) 当您想要在NewPage()中创建新页面时， AllocatePage私有方法为BufferPoolManager提供唯一的新页面 id。 获取latch，若free_list_不空，则取出free_list_的第一个元素（也可以不是第一个）作为frame_id，然后pop掉。否则，用LRUKReplacer的Evict方法获取一个frame_id，若驱逐失败，直接返回nullptr，驱逐成功则先从page_table_中erase掉该frame_id对应的page。 通过pages数组和frame_id获取该页面，如果该页是脏页，需要先写回磁盘，了解promise和future的使用方法。 page = pages_ + frame_id; if (page-\u003eIsDirty()) { // use promise and future to implement the communication between threads auto promise = disk_scheduler_-\u003eCreatePromise(); auto future = promise.get_future(); disk_scheduler_-\u003eSchedule({true, page-\u003eGetData(), page-\u003eGetPageId(), std::move(promise)}); // wait till promise is fulfilled future.get(); page-\u003eis_dirty_ = false; } 用AllocatePage()分配一个页面id，执行一系列初始化，返回页面。 page-\u003epage_id_ = AllocatePage(); page-\u003eResetMemory(); page-\u003epin_count_ = 1; page_table_[page-\u003epage_id_] = frame_id; replacer_-\u003eSetEvictable(frame_id, false); replacer_-\u003eRecordAccess(frame_id); *page_id = page-\u003epage_id_; ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:1","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"FetchPage(page_id_t page_id) 对于FetchPage ，如果空闲列表中没有可用页面且所有其他页面当前均已固定，则应返回 nullptr。 获取latch，如果page_id等于INVALID_PAGE_ID，返回nullptr。 如果在page_table_中找到了该page_id，则取出对应的frame_id，然后用pages数组得到page。replacer_记录它的访问、置为不可驱逐、pin加一。返回该page。 若是没有找到，则要通过free_list_或者驱逐来获得一个frame_id，同理NewPage()的时候也要先执行写回磁盘。 修改page_table_，同理NewPage()执行一系列初始化，然后利用disk_scheduler_修改从磁盘读取物理页面，存入page后返回。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:2","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"UnpinPage(page_id_t page_id, bool is_dirty) 对于UnpinPage ， is_dirty 参数跟踪页面在固定时是否被修改。 获取latch，如果page_table_中没找到，返回false。 拿到page，若是pin_count_以及为0，返回false。 pin_count_减1，若减完之后为0，置为可驱逐，然后注意is_dirty_设置为is_dirty || page-\u003eis_dirty_。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:3","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"FlushPage(page_id_t page_id) FlushPage应该刷新页面，无论其 pin 状态如何。 获取latch，page_id不合法或者没在page_table_中没找到，返回false。 拿到page，用disk_scheduler_写回磁盘。is_dirty_置为false。 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:4","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"DeletePage(page_id_t page_id) DeallocatePage()方法是一个空操作，它模拟释放磁盘上的页面，您应该在DeletePage()实现中调用它。 获取latch，若page_id不合法，返回false。若是在page_table_中没找到，先执行DeallocatePage(page_id)，返回true。 拿到page，如果pin_count_不为0，返回false。 执行一系列删除相关操作后DeallocatePage(page_id)。 page_table_.erase(page_id); replacer_-\u003eRemove(frame_id); free_list_.emplace_back(frame_id); page-\u003eResetMemory(); page-\u003epage_id_ = INVALID_PAGE_ID; page-\u003eis_dirty_ = false; page-\u003epin_count_ = 0; DeallocatePage(page_id); ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:5","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"FlushAllPages() 写回所有页面到磁盘 ","date":"2025-01-13","objectID":"/cmu15445-buffer_pool/:4:6","tags":null,"title":"Cmu15445 Buffer Pool","uri":"/cmu15445-buffer_pool/"},{"categories":null,"content":"Trie trie 实现的是键值存储，字符串键可以映射到任何类型值。键的值存储在改键的最后一个字符的终端节点。例如将（“ab”， 1） 和 （“ac”， “val”） 插入到 trie 中。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:0:0","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"copy-on-write 写时复制，任何操作都不会修改原先的trie节点，而是会为修改后的数据创建新节点，并为修改后的trie返回新的根节点。这样做可以很方便的访问旧的trie，撤销操作也容易。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:1:0","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"插入 例如对之前的trie插入（“ab”， 2），这里会复用原先树中的两个字节点，并创建一个新的值节点2，然后用他们三个来创建新的Node2。 然后插入（“b”， 3），创建一个新的root、一个新的值节点3并复用之前的节点。这样操作前后的内容，只要有root，就可以访问当时的完整数据。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:1:1","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"删除 父节点也可以有值，例如上述trie可以插入（“a”， “abc”）。删除的时候先删除对应的节点，之后要注意的是，需要清除所有不必要的节点（即没有值且没有子节点的节点）。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:1:2","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"implement Get(key) 获取 key 对应的值。 遍历key的每一个字符，从当前root开始，通过查看每个字符是否在current-\u003echildren_中，没找到或者current为空直接返回nullptr，找到了就把current更新为current-\u003echildren_.at(ch)。 经过上一步骤之后，现在current就是key对应的值节点。然后利用dynamic_cast把它转换为const TrieNodeWithValue\u003cT\u003e *。若是转换后为nullptr，说明类型不匹配，直接返回nullptr，否则返回该节点。 auto *node{dynamic_cast\u003cconst TrieNodeWithValue\u003cT\u003e *\u003e(current.get())}; Put(key, value) 为 key 设置对应的值。如果键已存在，则覆盖现有值。请注意，值的类型可能是不可复制的（即 std：：unique_ptr）。此方法返回一个新的 trie。 如果key.empty()。判断root是否有孩子，若有孩子，用孩子和传入的value创建一个new_root返回，否则直接用value创建new_root返回。 if (root_-\u003echildren_.empty()) { new_root = std::make_unique\u003cTrieNodeWithValue\u003cT\u003e\u003e(std::move(val_p)); } else { new_root = std::make_unique\u003cTrieNodeWithValue\u003cT\u003e\u003e(root_-\u003echildren_, std::move(val_p)); } 利用节点的Clone()函数，从root开始克隆，先判断root是否存在，若不存在则用std::make_shared\u003cTrieNode\u003e()新建一个TrieNode。该节点即为一会要返回的新的root。 开始遍历key。每次遍历，先判断若当前字符不是key的最后一个字符，进行下述操作：在当前节点clone_current的孩子中找，若找到了则把这个孩子Clone()一份作为clone_current的新孩子，然后更新clone_current为这个孩子，继续往下找。若没找到该孩子，则创建一个新的TrieNode。 若是遍历到最后一个字符，判断是否有对应的孩子，同理1，若有则用这个孩子的children_和传入的value创建一个TrieNodeWithValue，若没有就直接用value创建。建好了之后连上当前的clone_current-\u003echildren_[ch] = new_child就大功告成。返回新的root。 Remove(key) 删除 key 的值。此方法返回一个新的 trie。 还是先处理边界情况，若!root_直接返回*this。若key.empty()：先克隆当前root，有孩子就用孩子创建一个无值节点返回，没孩子直接返回nullptr。 开始遍历key，任何一个节点没找到则直接返回*this，并把路上经过的每一个节点克隆一遍放入一个vector（或者直接用stack）中，并前后连接上。遍历完后把最后一个节点的is_value_node置为false。 // clone every node in key into vec. clone_current = std::shared_ptr\u003cTrieNode\u003e(current-\u003eClone()); vec.back()-\u003echildren_[ch] = clone_current; vec.push_back(clone_current); 自底向上删除，从vector的最后一个节点往前。若!is_value_node：判断若没有孩子，则erase掉该节点，否则用孩子创建一个TrieNode的无值节点替换。 判断新root是否为空且!is_value_node，若满足则返回nullptr。否则返回新root。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:1:3","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"注意 所有操作都不会在原始trie上修改，应该是创建一个新的trie节点并尽可能复用旧的trie节点。 创建新节点时将其转换为智能指针，复用节点时可以复制std::shared_ptr\u003cTrieNode\u003e，智能共享指针的增加不会复制底层数据，且会在没有人引用底层对象时自动释放对象。 std::move()可以把左值转换为右值。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:1:4","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"Concurrent Key-Value Store ","date":"2025-01-13","objectID":"/cmu15445-trie/:2:0","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"Triestore 在拥有可在单线程环境中使用的写入时复制trie后，为多线程环境实现并发键值存储。并发键值存储应同时为多个读取器和单个写入器提供服务。 此外，如果我们从trie获得对值的引用，那么无论我们如何修改 trie，我们都应该能够访问它。Trie的Get函数仅返回一个指针。如果存储此值的trie节点已被删除，则指针将悬空。因此，在 TrieStore 中，我们返回一个ValueGuard，它存储对值的引用和对应于 trie 结构根的TrieNode，以便在我们存储ValueGuard时可以访问该值。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:2:1","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"implement Get(key) 拿到root lock，获取root，然后释放root lock。注意在持有root lock的时候，先不要查找trie里的值。 查找trie里的值。 如果找到值了，返回一个ValueGuard对象，它持有对值的引用和对应的root，否则返回std::nullopt。 Put(key, value) 获取write_lock_，执行put。 获取root lock，修改root_为新的root。 Remove(key) 获取write_lock_，执行remove。 获取root lock，修改root_为新的root。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:2:2","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"SQL String Functions 需要实现上层和下层SQL函数。这可以分2个步骤完成： 在 string_expression.h 中实现函数逻辑。 在 BusTub 中注册函数，以便 SQL 框架可以在用户执行 SQL 时以 plan_func_call.cpp 调用你的函数。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:3:0","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"实现函数逻辑 简单的大小写转换，利用std::toupper和std::tolower。 ","date":"2025-01-13","objectID":"/cmu15445-trie/:3:1","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"},{"categories":null,"content":"注册函数 auto Planner::GetFuncCallFromFactory(const std::string \u0026func_name, std::vector\u003cAbstractExpressionRef\u003e args) -\u003e AbstractExpressionRef { // 1. check if the parsed function name is \"lower\" or \"upper\". // 2. verify the number of args (should be 1), refer to the test cases for when you should throw an `Exception`. // 3. return a `StringExpression` std::shared_ptr. if ((func_name == \"lower\" || func_name == \"upper\") \u0026\u0026 args.size() == 1) { return static_cast\u003cstd::shared_ptr\u003cStringExpression\u003e\u003e(std::make_shared\u003cStringExpression\u003e( args[0], func_name == \"lower\" ? StringExpressionType::Lower : StringExpressionType::Upper)); } throw Exception(fmt::format(\"func call {} not supported in planner yet\", func_name)); } ","date":"2025-01-13","objectID":"/cmu15445-trie/:3:2","tags":null,"title":"Cmu15445 Trie","uri":"/cmu15445-trie/"}]